{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.metrics import recall_score,roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading important files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "e1=0\n",
    "e2=0\n",
    "e3=0\n",
    "e4=0\n",
    "#loading data\n",
    "try:\n",
    "    data=pd.read_csv('sensor.csv',index_col=0)\n",
    "    time=list(data['timestamp'].loc[9:].values)\n",
    "except:\n",
    "    e1=1\n",
    "\n",
    "#loading normalizer\n",
    "try:\n",
    "    if not os.path.isfile('model_scaler_s10_std'):\n",
    "        with ZipFile('model_scaler.zip', 'r') as zipObj:\n",
    "            zipObj.extractall()\n",
    "        zipObj.close()\n",
    "except:\n",
    "    e2=1\n",
    "    \n",
    "#loading model\n",
    "try:\n",
    "    model = pickle.load(open('final_model', 'rb'))\n",
    "except:\n",
    "    e3=1\n",
    "#na replacement load\n",
    "try:\n",
    "    na_replace = np.load('NA_replace')\n",
    "except:\n",
    "    e4=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_1(samples):\n",
    "    if e1==1:\n",
    "        print('Please store sensor.csv file in current directory, it is not found please check and rerun whole notebook')\n",
    "    if e2==1:\n",
    "        print('Please store model_scaler in current directory, it is not found please check and rerun whole notebook')\n",
    "    if e3==1:\n",
    "        print('Please store final_model in current directory, it is not found please check and rerun whole notebook')\n",
    "    if e4==1:\n",
    "        print('Please store NA_replace in current directory, it is not found please check and rerun whole notebook')\n",
    "    \n",
    "    s=0\n",
    "    for sample in samples:\n",
    "        if len(samples.shape)==1:\n",
    "            sample=samples\n",
    "        if sample[0] not in time:\n",
    "            return \"invalid data point given please check timestamp is should be in range '2018-04-01 00:59:00' to '2018-08-31 23:59:00'\"\n",
    "        if len(sample) !=53:\n",
    "            return 'all the 52 reading from the sensor is not given please check'\n",
    "        index=data[data['timestamp']==sample[0]].index[0]\n",
    "        window=data.loc[index-9:index-1].copy()\n",
    "        window.drop(['machine_status'],inplace=True,axis=1)\n",
    "        window=window.append(pd.Series(sample, index=window.columns), ignore_index=True)\n",
    "        window.drop(['sensor_01','sensor_03','sensor_14','sensor_15','sensor_16','sensor_17','sensor_18','sensor_19','sensor_20','sensor_21',\n",
    "           'sensor_22','sensor_23','sensor_24','sensor_25','sensor_26','sensor_27','sensor_28','sensor_29','sensor_30',\n",
    "           'sensor_31','sensor_33','sensor_34','sensor_37','sensor_36','sensor_48','timestamp'],\n",
    "            inplace=True,axis=1)\n",
    "    \n",
    "        for i in range(len(window.columns)):\n",
    "            window[window.columns[i]]=window[window.columns[i]].fillna(na_replace[i])\n",
    "    \n",
    "        columns=[]\n",
    "        for col in window.columns:\n",
    "            columns.append('s{0}_median'.format(col[7:])) #to select sensor number\n",
    "            columns.append('s{0}_mean'.format(col[7:]))\n",
    "            columns.append('s{0}_std'.format(col[7:]))\n",
    "            columns.append('s{0}_min'.format(col[7:]))\n",
    "            columns.append('s{0}_max'.format(col[7:]))\n",
    "        features=[]\n",
    "        data_window=pd.DataFrame(columns=columns)\n",
    "        for col in window.columns:\n",
    "                features.append(window[col].median())#calculating features\n",
    "                features.append(window[col].mean())\n",
    "                features.append(window[col].std())\n",
    "                features.append(window[col].min())\n",
    "                features.append(window[col].max())\n",
    "        data_window=data_window.append(pd.Series(features, index=columns), ignore_index=True)\n",
    "\n",
    "        for col in data_window.columns:\n",
    "            scaler = pickle.load(open('model_scaler_{0}'.format(col), 'rb'))\n",
    "            data_window[col]=scaler.transform(data_window[col].values.reshape(1, -1))\n",
    "        label=model.predict(data_window)\n",
    "        if label==0:\n",
    "            print('Machine status for sample {0} at time {1} : \"NORMAL\"'.format(s,sample[0])) \n",
    "        else:\n",
    "            print('Machine status for sample {0} at time {1} : \"BROKEN\"'.format(s,sample[0]))\n",
    "        if len(samples.shape)==1:\n",
    "            break\n",
    "        s=s+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_2(samples):\n",
    "    if e1==1:\n",
    "        print('Please store sensor.csv file in current directory, it is not found please check and rerun whole notebook')\n",
    "    if e2==1:\n",
    "        print('Please store model_scaler in current directory, it is not found please check and rerun whole notebook')\n",
    "    if e3==1:\n",
    "        print('Please store final_model in current directory, it is not found please check and rerun whole notebook')\n",
    "    if e4==1:\n",
    "        print('Please store NA_replace in current directory, it is not found please check and rerun whole notebook')\n",
    "    \n",
    "    s=0\n",
    "    pred_labels=[]\n",
    "    true_labels=[]\n",
    "    pred_proba=[]\n",
    "    for sample in samples:\n",
    "        if len(samples.shape)==1:\n",
    "            sample=samples\n",
    "        if sample[0] not in time:\n",
    "            return \"invalid data point given please check timestamp is should be in range '2018-04-01 00:59:00' to '2018-08-31 23:59:00'\"\n",
    "        if len(sample) !=54:\n",
    "            return 'all the 52 reading from the sensor with timestamp and class label is not given please check'\n",
    "        true_labels.append(sample[-1])\n",
    "        index=data[data['timestamp']==sample[0]].index[0]\n",
    "        window=data.loc[index-9:index-1].copy()\n",
    "        window=window.append(pd.Series(sample, index=window.columns), ignore_index=True)\n",
    "        window.drop(['sensor_01','sensor_03','sensor_14','sensor_15','sensor_16','sensor_17','sensor_18','sensor_19','sensor_20','sensor_21',\n",
    "           'sensor_22','sensor_23','sensor_24','sensor_25','sensor_26','sensor_27','sensor_28','sensor_29','sensor_30',\n",
    "           'sensor_31','sensor_33','sensor_34','sensor_37','sensor_36','sensor_48','timestamp','machine_status'],\n",
    "            inplace=True,axis=1)\n",
    "    \n",
    "        for i in range(len(window.columns)):\n",
    "            window[window.columns[i]]=window[window.columns[i]].fillna(na_replace[i])\n",
    "    \n",
    "        columns=[]\n",
    "        for col in window.columns:\n",
    "            columns.append('s{0}_median'.format(col[7:])) #to select sensor number\n",
    "            columns.append('s{0}_mean'.format(col[7:]))\n",
    "            columns.append('s{0}_std'.format(col[7:]))\n",
    "            columns.append('s{0}_min'.format(col[7:]))\n",
    "            columns.append('s{0}_max'.format(col[7:]))\n",
    "        features=[]\n",
    "        data_window=pd.DataFrame(columns=columns)\n",
    "        for col in window.columns:\n",
    "                features.append(window[col].median())#calculating features\n",
    "                features.append(window[col].mean())\n",
    "                features.append(window[col].std())\n",
    "                features.append(window[col].min())\n",
    "                features.append(window[col].max())\n",
    "        data_window=data_window.append(pd.Series(features, index=columns), ignore_index=True)\n",
    "\n",
    "        for col in data_window.columns:\n",
    "            scaler = pickle.load(open('model_scaler_{0}'.format(col), 'rb'))\n",
    "            data_window[col]=scaler.transform(data_window[col].values.reshape(1, -1))\n",
    "        label=model.predict(data_window)\n",
    "        pred_proba.append(model.predict_proba(data_window)[:,1].tolist()[0])\n",
    "        pred_labels.append(label)\n",
    "        if len(samples.shape)==1:\n",
    "            break\n",
    "        s=s+1\n",
    "    print('Recall score is:',recall_score(true_labels,pred_labels))\n",
    "    try:\n",
    "        print('AUC score is:',roc_auc_score(true_labels,pred_proba))\n",
    "    except ValueError:\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_machine_status(start,end):\n",
    "    '''\n",
    "    return class label for each sample. it take each sample and check machine status after 5 minute in window of size 10,\n",
    "    if there is 'BROKEN'  or 'RECOVERING' present in 10 minutes window then class label is 1.\n",
    "    '''\n",
    "    start_index=data[data['timestamp']==start].index[0]\n",
    "    end_index=data[data['timestamp']==end].index[0]\n",
    "    label=[]\n",
    "    for index in range(start_index,end_index+1):\n",
    "        a=data['machine_status'].loc[index+5:index+15].values\n",
    "        if (('BROKEN' in a) or ('RECOVERING' in a)):\n",
    "            label.append(1)\n",
    "        else:\n",
    "            label.append(0)\n",
    "    return label\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Failure dates with recovering time:\n",
    "- failure 1 at 2018-04-12 21:55:00, recovering time is 15.733333333333333 hours\n",
    "- failure 2 at 2018-04-18 00:30:00, recovering time is 51.833333333333336 hours\n",
    "- failure 3 at 2018-05-19 03:18:00, recovering time is 21.866666666666667 hours\n",
    "- failure 4 at 2018-05-25 00:30:00, recovering time is 10.083333333333334 hours\n",
    "- failure 5 at 2018-06-28 22:00:00, recovering time is 139.83333333333334 hours\n",
    "- failure 6 at 2018-07-08 00:11:00, recovering time is 0.6833333333333333 hours\n",
    "- failure 7 at 2018-07-25 14:00:00, recovering time is 1.25 hours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 1 : predicting machine status after 5 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine status for sample 0 at time 2018-06-28 21:40:00 : \"BROKEN\"\n"
     ]
    }
   ],
   "source": [
    "function_1(data[data['timestamp']=='2018-06-28 21:40:00'][data.columns[0:-1]].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine status for sample 0 at time 2018-07-08 00:06:00 : \"BROKEN\"\n"
     ]
    }
   ],
   "source": [
    "function_1(data[data['timestamp']=='2018-07-08 00:06:00'][data.columns[0:-1]].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine status for sample 0 at time 2018-07-08 00:00:00 : \"NORMAL\"\n"
     ]
    }
   ],
   "source": [
    "function_1(data[data['timestamp']=='2018-07-08 00:00:00'][data.columns[0:-1]].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine status for sample 0 at time 2018-07-25 03:00:00 : \"NORMAL\"\n"
     ]
    }
   ],
   "source": [
    "function_1(data[data['timestamp']=='2018-07-25 03:00:00'][data.columns[0:-1]].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine status for sample 0 at time 2018-07-25 13:55:00 : \"BROKEN\"\n"
     ]
    }
   ],
   "source": [
    "function_1(data[data['timestamp']=='2018-07-25 13:55:00'][data.columns[0:-1]].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine status for sample 0 at time 2018-04-04 04:44:00 : \"NORMAL\"\n",
      "Machine status for sample 1 at time 2018-04-04 04:45:00 : \"NORMAL\"\n",
      "Machine status for sample 2 at time 2018-04-04 04:46:00 : \"NORMAL\"\n",
      "Machine status for sample 3 at time 2018-04-04 04:47:00 : \"NORMAL\"\n",
      "Machine status for sample 4 at time 2018-04-04 04:48:00 : \"NORMAL\"\n"
     ]
    }
   ],
   "source": [
    "function_1(data[data.columns[0:-1]].iloc[4604:4609].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 2 : printing recall score for given  dataset\n",
    "- to get recall score, 1st we have to get class label for given sample after 5 minutes, hence we have written a function nameget_machine_status.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\anna\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall score is: 1.0\n"
     ]
    }
   ],
   "source": [
    "start='2018-04-12 21:55:00'\n",
    "end='2018-04-12 22:00:00'\n",
    "label=get_machine_status(start, end)\n",
    "val_data=data.loc[data[data['timestamp']==start].index[0]:data[data['timestamp']==end].index[0]]\n",
    "val_data['machine_status']=label\n",
    "function_2(val_data.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\anna\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall score is: 0.9936170212765958\n",
      "AUC score is: 0.9998653995848469\n"
     ]
    }
   ],
   "source": [
    "start='2018-04-12 21:55:00'\n",
    "end='2018-04-14 00:30:00'\n",
    "label=get_machine_status(start, end)\n",
    "val_data=data.loc[data[data['timestamp']==start].index[0]:data[data['timestamp']==end].index[0]]\n",
    "val_data['machine_status']=label\n",
    "function_2(val_data.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\anna\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall score is: 0.9506172839506173\n",
      "AUC score is: 0.941189674523008\n"
     ]
    }
   ],
   "source": [
    "start='2018-07-25 13:50:00'\n",
    "end='2018-07-25 17:00:00'\n",
    "label=get_machine_status(start, end)\n",
    "val_data=data.loc[data[data['timestamp']==start].index[0]:data[data['timestamp']==end].index[0]]\n",
    "val_data['machine_status']=label\n",
    "function_2(val_data.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
